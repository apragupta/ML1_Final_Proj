{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prerequisite-nickname",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T09:32:33.752396Z",
     "start_time": "2021-04-01T09:32:33.749396Z"
    }
   },
   "source": [
    "# Extracting and and saving image features using different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposed-concept",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T10:42:13.162418Z",
     "start_time": "2021-04-01T10:42:10.904931Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#initialization code required to make tensorflow work on my systemabs\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "norman-front",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:07:18.134936Z",
     "start_time": "2021-04-01T11:07:18.130928Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'initial_sample'\n",
    "dir_path = os.path.join(r'data',data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "velvet-attribute",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:07:18.759915Z",
     "start_time": "2021-04-01T11:07:18.662720Z"
    }
   },
   "outputs": [],
   "source": [
    "##Load meta_data with image path from root\n",
    "data_df = pd.read_csv('data/initial_sample/sent_added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "inner-satellite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:07:19.125014Z",
     "start_time": "2021-04-01T11:07:19.121011Z"
    }
   },
   "outputs": [],
   "source": [
    "#all image paths in this set\n",
    "image_paths = data_df['image_path'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-indication",
   "metadata": {},
   "source": [
    "## InceptionV3 pretrained model embeddings. \n",
    "\n",
    "Insipration from [this](https://www.tensorflow.org/tutorials/text/image_captioning) tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "regulated-dominican",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:07:21.534216Z",
     "start_time": "2021-04-01T11:07:21.530216Z"
    }
   },
   "outputs": [],
   "source": [
    "#we define the pretrained model we are going to use. The weights are pretrained with image net and we only load evrything up to the last layer\n",
    "def init_inception_v3_model():\n",
    "    \"\"\"\n",
    "    Returns a pretrained inception V3 model without final layer to use to output embeddings\n",
    "    \"\"\"\n",
    "    embeddings_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "    input_layer = embeddings_model.input\n",
    "    output_layer = embeddings_model.layers[-1].output\n",
    "    inception_v3_feature_extractor = tf.keras.Model(input_layer,output_layer)\n",
    "    return inception_v3_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "parental-factory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:07:22.775788Z",
     "start_time": "2021-04-01T11:07:22.771794Z"
    }
   },
   "outputs": [],
   "source": [
    "#we need this helper function to put into the preprocessing pipeline\n",
    "def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    #this is the input size InceptionV3 takes in\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "civilian-china",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:07:23.924891Z",
     "start_time": "2021-04-01T11:07:23.920889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apra\\Desktop\\SPRING 2020\\DS 4400\\ML1_Final_Proj\n"
     ]
    }
   ],
   "source": [
    "#os.chdir(cwd)\n",
    "#cwd = os.getcwd()\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stunning-perry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:15:59.872229Z",
     "start_time": "2021-04-01T11:15:59.866228Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_images_with_inception_v3(image_paths, outpath):\n",
    "    \"\"\"\n",
    "    embeds the images in the paths of the given dataframe in the given path into inception v3 embeddings\n",
    "    and saves them in a directory with the given name.\n",
    "    \"\"\"\n",
    "    #save current directory\n",
    "    cwd = os.getcwd()\n",
    "    #load and initialize the pretrained model\n",
    "    \n",
    "    inception_v3_feature_extractor = init_inception_v3_model()\n",
    "    \n",
    "\n",
    "    #we use this data pipeline from tensorflow\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "    #this runs load_image on every image in the dataset in a batched manner\n",
    "    #according to some research an RTX 20260 might work well with a batch size of 32, can be tuned furtherabs\n",
    "    dataset = dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(32)\n",
    "\n",
    "    #change directory to directory we want to save embeddings in\n",
    "\n",
    "    for image, image_path in tqdm(dataset):\n",
    "        batch_embeddings = inception_v3_feature_extractor(image)\n",
    "        #reshape batch embeddings to one embedding per image\n",
    "        batch_embeddings = tf.reshape(batch_embeddings, \n",
    "                                     (batch_embeddings.shape[0], -1, batch_embeddings.shape[3]))\n",
    "\n",
    "        for batch_embedding, path in zip(batch_embeddings,image_path):\n",
    "            image_num = os.path.basename(path.numpy().decode(\"utf-8\"))\n",
    "            #save numpy embedding to current directory\n",
    "            os.chdir(outpath)\n",
    "            np.save(image_num,batch_embedding.numpy())\n",
    "            os.chdir(cwd)\n",
    "    #change back to cwd\n",
    "    os.chdir(cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will first attempt the pipeline on a few hundred samples to see if everything is fine\n",
    "num_samples = 100\n",
    "sample_image_paths = np.random.choice(image_paths, size=num_samples, replace = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "elect-headquarters",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:09:03.264294Z",
     "start_time": "2021-04-01T11:09:03.241515Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embeddings_dir_name = 'inception_v3_embeddings_sample_100'\n",
    "#create directory we want to store embeddings in and change to that directory\n",
    "inception_v3_embeddings_directory = os.path.join(dir_path, embeddings_dir_name)\n",
    "os.mkdir(inception_v3_embeddings_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "raised-bargain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:09:22.512770Z",
     "start_time": "2021-04-01T11:09:19.935366Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_images_with_inception_v3(sample_image_paths, inception_v3_embeddings_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-commerce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T10:26:44.779161Z",
     "start_time": "2021-04-01T10:26:44.776178Z"
    }
   },
   "source": [
    "### InceptionV3 model embeddings on 30k sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dirty-bread",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:29:15.505215Z",
     "start_time": "2021-04-01T11:29:15.502221Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '30k_sample'\n",
    "dir_path = os.path.join(r'data',data_dir)\n",
    "meta_data_path = os.path.join(dir_path, 'meta_data')\n",
    "images_dir_path = os.path.join(dir_path, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "popular-snapshot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:29:17.105934Z",
     "start_time": "2021-04-01T11:29:16.796211Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(meta_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "internal-lucas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:29:17.558381Z",
     "start_time": "2021-04-01T11:29:17.553387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29968"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "stuffed-stanley",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:29:22.343432Z",
     "start_time": "2021-04-01T11:29:22.274663Z"
    }
   },
   "outputs": [],
   "source": [
    "meta_df['image_path'] = meta_df['index'].apply(lambda p: os.path.join(images_dir_path, str(p) + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "athletic-gothic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:29:23.673834Z",
     "start_time": "2021-04-01T11:29:23.670829Z"
    }
   },
   "outputs": [],
   "source": [
    "image_paths = meta_df['image_path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "measured-corpus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:29:56.773850Z",
     "start_time": "2021-04-01T11:29:56.769850Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#we will first attempt the pipeline on a few hundred samples to see if everything is fine\n",
    "num_samples = 100\n",
    "sample_image_paths = np.random.choice(image_paths, size=num_samples, replace = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "absent-cleaning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:30:07.785152Z",
     "start_time": "2021-04-01T11:30:07.781144Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_dir_name = 'inception_v3_embeddings'\n",
    "#create directory we want to store embeddings in and change to that directory\n",
    "inception_v3_embeddings_directory = os.path.join(dir_path, embeddings_dir_name)\n",
    "os.mkdir(inception_v3_embeddings_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "muslim-lafayette",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:33:50.219613Z",
     "start_time": "2021-04-01T11:31:17.177993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████▎                         | 636/937 [02:31<01:11,  4.20it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "jpeg::Uncompress failed. Invalid JPEG data or crop window.\n\t [[{{node DecodePng}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2113\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2114\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2577\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2578\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2579\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: jpeg::Uncompress failed. Invalid JPEG data or crop window.\n\t [[{{node DecodePng}}]] [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-b2bd2ec1b538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membed_images_with_inception_v3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minception_v3_embeddings_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-ad8dda08c760>\u001b[0m in \u001b[0;36membed_images_with_inception_v3\u001b[1;34m(image_paths, outpath)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#change directory to directory we want to save embeddings in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mbatch_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minception_v3_feature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#reshape batch embeddings to one embedding per image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2114\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2116\u001b[1;33m       \u001b[0mexecutor_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ML1_Final_Proj\\lib\\site-packages\\tensorflow\\python\\eager\\executor.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: jpeg::Uncompress failed. Invalid JPEG data or crop window.\n\t [[{{node DecodePng}}]]"
     ]
    }
   ],
   "source": [
    "embed_images_with_inception_v3(image_paths, inception_v3_embeddings_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-grocery",
   "metadata": {},
   "source": [
    "## Appendix: dropping rows in metadata for cells that do not exist and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "greek-shepherd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:27:10.022134Z",
     "start_time": "2021-04-01T11:27:03.668189Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#quick  code for dropping rows pertaining to images that do not exist\n",
    "image_names = os.listdir(images_dir_path)\n",
    "image_names = [i.split('.')[0] for i in image_names]\n",
    "\n",
    "for idx,file in meta_df.iterrows():\n",
    "    file = file['index']\n",
    "    if not (str(file) in image_names):\n",
    "        #meta_df.drop(labels=[idx], axis='index', inplace=True)\n",
    "        print(\"dropped\", idx,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "junior-constraint",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-01T11:29:03.535050Z",
     "start_time": "2021-04-01T11:29:03.169321Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "meta_df.to_csv(meta_data_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-translator",
   "metadata": {},
   "source": [
    "### Errors encountered/fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-genome",
   "metadata": {},
   "source": [
    "more corrupt data: https://github.com/tensorflow/tpu/issues/455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-resistance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
